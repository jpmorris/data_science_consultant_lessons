# Overview of GenAI Industry, Tools, and Resources

This analysis was preformed on March 18, 2025 and will certainly be out of date quickly. We want to
analyze the current state of the industry in particular the vibecoding resources.

## Review of Industry Opinions on Important Topics

### Risk

#### Terminology

- AGI - Artificial General Intelligence
- ASI - Artificial Super Intelligence
- UBI - Universal Basic Income

- Three Godfathers of AI: Jeff Hinton, Yann Lecun, Yoshua Bengio
  - Won the Turing Award in 2018

#### Expert Opinions

<!-- disable word wrap in vscode make the table more readable: alt+z  -->
<!-- prettier-ignore-start -->
| Person            | Occupation                                       | Opinion                                                                                                                 | Link                                                                                                                                             |
|-------------------|--------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------|
| Jeff Hinton       | AI Researcher                                    | Believes in widespread job loss and advocates for UBI                                                                   | https://blog.getodin.ai/ai-takes-jobs-odin-offers-hope-geoffrey-hinton/                                                                          |
| Andrew Ng         | AI Researcher                                    | Massive Boost in Productivity, create new jobs, but some losses are inevitable                                          |                                                                                                                                                  |
| Yann Lecun        | AI Researcher                                    | Won't take over the world or permanently destroy jobs.                                                                  | https://www.bbc.com/news/technology-65886125#:~:text=One%20of%20the%20three%20%22godfathers,humanity%20were%20%22preposterously%20ridiculous%22. |
|                   | AI Researcher                                    |                                                                                                                         |                                                                                                                                                  |
| Yoshua Bengio     | AI Researcher                                    | Will transform job market by replacing specific roles, it wont 'steal' jobs                                             |                                                                                                                                                  |
| Gary Marcus       | Cognitive Scientist, Founder of two AI Companies | Will transform jobs; wont take massively relplace jobs in the short term                                                |                                                                                                                                                  |
| Dario Amodei      | CEO, Anthropic                                   | "In the next 3 to 6 months, AI is writing 90% of Code"                                                                  |                                                                                                                                                  |
| Kevin Roose       | Journalist, NYTimes                              | "Powerful AI is Coming. We're not Ready.                                                                                | https://www.nytimes.com/2025/03/14/technology/why-im-feeling-the-agi.html                                                                        |
| Ezra Klein        | Journalist, NYTimes                              | "Government Knows AGI Is Coming"                                                                                        | https://www.nytimes.com/2025/03/04/opinion/ezra-klein-podcast-ben-buchanan.html                                                                  |
| Eliezer Yudkowsky | AI Researcher                                    | Massive Job Losses, most likely end of the world                                                                        |                                                                                                                                                  |
| Primogen          | Software Developer (youtube)                     | Tools create bad code, maybe help some productivity, but not putting developers out of a job in the near to medium term |                                                                                                                                                  |
<!-- prettier-ignore-end -->

#### Prediction sites

- Metaculus
  - "When will the first general AI system be devised, tested, and publically announced?"
    - https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/
  - "When will the first weakly general AI system be devised, tested, and publically announced?"
    - https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/
- Manifold
  - "AGI When?" 2033
    - https://manifold.markets/ManifoldAI/agi-when-resolves-to-the-year-in-wh-d5c5ad8e4708
  - "Will we get AGI before 2027" 16%
    - https://manifold.markets/RemNi/will-we-get-agi-before-2027-d7b5f2b00ace
- Kalshi
  - "When will OpenAI achieve AGI?" 64% before 2030
    - https://kalshi.com/markets/kxoaiagi/openai-achieves-agi
- Polymarket
  - "OpenAI announces it has achieved AGI in 2025" 22% Chance
    - https://polymarket.com/event/openai-announces-it-has-achieved-agi-in-2025?tid=1742315921166

#### Classes of Risk

- Will I lose my job in N years?
- Is there a society-level risk (misinformation, scams, hacking etc.)
- Is there a humanity-level risk (state-level threat; p-doom scenarios)
  - P(Doom) - subjective probability of existentially catastrophic outcomes (i.e. 'doom') as the
    result of artificial intelligence in the long run.
    - https://en.wikipedia.org/wiki/P(doom)

We'll only be focusing on the first case of personal job risk for a data scientist.

#### A priori arguments regarding job loss

- Bull (AI pumper): AI is already breaking through benchmarks, and accomplishing impressive things
  better than humans. There is no reason to believe that these models wont improve.
- Bear (AI skeptic): Admission that a will improve does not mean it will improve forever.
  - We've been here before in other technologies
    - Driverless Cars
    - Crypto
    - GUT (Theory of Everything in physics)

In trying to decern between these two possibilities we want to look at the possible theoretical
limiations of current GenAI models and whether it seems likely that they would be overcome.

### Theoretical and Practical Limitations of Current GenAI Models

####

| Model   | Release Date       | Months Since Previous Release |
| ------- | ------------------ | ----------------------------- |
| GPT-2   | February 14, 2019  |                               |
| GPT-3   | June 11, 2020      | 15                            |
| GPT-3.5 | November 30, 2022  | 29                            |
| GPT-4   | March 14, 2023     | 3                             |
| GPT-4o  | May 13, 2024       | 13                            |
| GPT-o1  | September 12, 2024 | 3                             |
| GPT-o3  | January 31, 2025   | 4                             |
| GPT-4.5 | February 27, 2025  | 1                             |
| GPT-5   | Expected in 2025   |                               |

It has been 2 years since GPT-4. OpenAI has ben productizing their models, but if 'scale is all you
need' to AGI then why are they wasting time productizing models, AGI is the ultimate prize. This
suggests at least two possibilities:

1. OpenAI suffers from a **lack of data** after exhausting most quality training data on the
   internet it needs to find more data or synthesize data
2. The results of scaling have been lackluster and OpenAI doesn't think there are anymore benefits
   to scale

Some have rumored that 4.5 was a version decrement due to lack in performance. This is unconfirmed.
We do know that OpenAI seems to be waisting time with products with AGI is supposedly around the
corner (according to Sam Altman and others) which should supercharge them to create these very
products. Either they appear to have a bad business strategy or AGI is harder than they are letting
on.

The argument is that models may have exhausted the benefits of scaling however there may be scaling
laws with chain-of-thought and reasoning (taking more time with the model). This line of thought
seems to have a fundamental misunderstanding of what **scaling** laws are. One can't simply 'double
the amount of reasoning'. It is possible to increase the amount of time the model spends on Chain of
Thought but it's not clear that performance scales with scaling of 'reasoning' in the same way we
know data does in many models (that are data limited)

### Current technical limitations and possible solutions, if any

#### Lack of Data

##### Can you simulate data?

##### GenAI needs to interact in a Human's world with human interfaces (e.g. browser)

A possible solution is using agents and MCP (Model Context Protocol) to interact in this
human-designed world.

##### Arguments for fundamental limitations

## Review of Current Tools and Methods

## Vibecoding

Vibe coding is a new way of coding that is supposed to be more efficient and fun. It is a way of
coding that is supposed to be more efficient and fun. It is a way of coding that is supposed to be
more efficient and fun. It is a way of coding that is supposed to be more efficient and fun. It is a

<!-- prettier-ignore-start -->
| Task                                  | Prompt                                                                                                                          | Developer | Performance | Notes                                                                                      | Link |
|---------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|-----------|-------------|--------------------------------------------------------------------------------------------|------|
| Adding arguments to GCP Syntheize TTS |                                                                                                                                 | Me        | Great       | Adding simple arguments works very well (must be millions of examples in the training set) |      |
| Top sentence Length Finder            | I need code that takes in text as an argument and then parses between periods and displays the top 10 sentences.                | Me        | Very Good   | The regex didn't parse large spaces well, but was good enough for my use.                  |      |
| Spacy NLP Code:                       | Can you modify the code to create a texcat training loopfor training data which is the merge of train-cases and train_noncases. | Me        | Ok          | All models didn't understand Dagster integration, and some logic removing texcat component |      |

<!-- prettier-ignore-end -->

## Tools

- Devin AI
- Cursor
- Deep Research

## MCP

- MCP - Model Conext Protocol
  - Created by Anthropic - https://www.anthropic.com/news/model-context-protocol
